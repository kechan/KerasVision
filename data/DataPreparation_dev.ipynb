{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo on how to create a HDF5 dataset from raw images\n",
    "\n",
    "### Contents\n",
    "\n",
    "1. Prepare your data\n",
    "2. Define all expected common parameters\n",
    "3. Call generate_h5(...) to generate HDF5 dataset file\n",
    "4. Call load_all_data(...) to extract the data as np.array objects into your python env\n",
    "5. Check on the shape or content of the various np.array\n",
    "6. Check to visualize a randomly chosen image\n",
    "7. Sample code for Mini-batch access for bigger dataset\n",
    "8. References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import os\n",
    "import glob\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from data_util import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Prepare your data\n",
    "Put all images with the same label into each separate folder. Name the folder\n",
    "with the name of the target class. For example, if you have a binary classification \n",
    "task to identify cats vs non-cats. Put all your cats photo into a folder named \"cat\" and\n",
    "all the non-cats photos into another folder named \"non-cat\". \n",
    "\n",
    "#### 2. Define all expected common parameters\n",
    "* __data_path__ is the root directory containing all the folders holding images of each class (see above).\n",
    "* __shuffled_data__ is a boolean to determine if we should shuffle the data before saving into h5 file\n",
    "* __height, width__ are the resized height and width. It is assumed that in general, your photos may have different height and width, and they will have to be resized to these fixed values.\n",
    "* __data_order__ can either be 'tf' or 'th' (tensorflow vs. theano). I have only tested 'tf' for now, so just stick with that. The only difference I am aware of is 'tf' uses \"channel last\" with shape (m, h, w, c) and 'th' uses \"channel first\" with shape (m, c, h, w)\n",
    "* __outfile_path__ is the name of the output HDF5 file name.\n",
    "* __labels_to_classes_dictionary__ is a python dictionary with numeric string as key and the name of the class as values. E.g. {\"0\": \"non-cat\", \"1\": \"cat\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_data = True\n",
    "data_order = 'tf'\n",
    "#data_path = 'original'\n",
    "data_path = 'cropped/train'\n",
    "\n",
    "height = 64\n",
    "width = 64\n",
    "\n",
    "outfile_path = \"train_cropped_coin_\" + str(height) + \"_\" + str(width) + \".hdf5\"\n",
    "\n",
    "coin_dictionary = {\"0\": \"UNK\", \"1\": \"5c\", \"2\": \"10c\", \"3\": \"25c\", \"4\": \"$1\", \"5\": \"$2\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Call generate_h5(...) to generate HDF5 dataset file\n",
    "generate_h5 takes a few argument. Please see data_util.py for all details. Most of the important arguments are explained in Part 2 above. The method will save a file with name __outfile_path__ that is an HDF5 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data: 100/768\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'arr' does not have a suitable array shape for any mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-eda1087aa6a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m generate_h5(data_path, labels_to_classes_dictionary=coin_dictionary, \n\u001b[1;32m      2\u001b[0m             \u001b[0moutfile_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m             train_dev_test_ratio=[0.0, 0.0, 1.0])\n\u001b[0m",
      "\u001b[0;32m/Users/kelvinchan/Documents/CoinSee/data/data_util.pyc\u001b[0m in \u001b[0;36mgenerate_h5\u001b[0;34m(data_path, labels_to_classes_dictionary, outfile_path, shuffle_data, resize_height, resize_width, data_order, train_dev_test_ratio)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0maddr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_addrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresize_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# add any image pre-processing here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kelvinchan/Documents/TensorFlowStuff/lib/python2.7/site-packages/numpy/lib/utils.pyc\u001b[0m in \u001b[0;36mnewfunc\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;34m\"\"\"`arrayrange` is deprecated, use `arange` instead!\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mnewfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_set_function_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kelvinchan/Documents/TensorFlowStuff/lib/python2.7/site-packages/scipy/misc/pilutil.pyc\u001b[0m in \u001b[0;36mimresize\u001b[0;34m(arr, size, interp, mode)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \"\"\"\n\u001b[0;32m--> 554\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m     \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignedinteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kelvinchan/Documents/TensorFlowStuff/lib/python2.7/site-packages/numpy/lib/utils.pyc\u001b[0m in \u001b[0;36mnewfunc\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;34m\"\"\"`arrayrange` is deprecated, use `arange` instead!\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mnewfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_set_function_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kelvinchan/Documents/TensorFlowStuff/lib/python2.7/site-packages/scipy/misc/pilutil.pyc\u001b[0m in \u001b[0;36mtoimage\u001b[0;34m(arr, high, low, cmin, cmax, pal, mode, channel_axis)\u001b[0m\n\u001b[1;32m    324\u001b[0m                                 ((3 in shape) or (4 in shape)))\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         raise ValueError(\"'arr' does not have a suitable array shape for \"\n\u001b[0m\u001b[1;32m    327\u001b[0m                          \"any mode.\")\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'arr' does not have a suitable array shape for any mode."
     ]
    }
   ],
   "source": [
    "generate_h5(data_path, labels_to_classes_dictionary=coin_dictionary, \n",
    "            outfile_path=outfile_path, resize_height=height, resize_width=width, \n",
    "            train_dev_test_ratio=[1.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Call load_all_data(...) to extract the data as np.array objects into your python env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y_orig, dev_set_x_orig, dev_set_y_orig, test_set_x_orig, test_set_y_orig, classes = load_all_data(outfile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Check on the shape or content of the various np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape: \" + str(train_set_x_orig.shape))\n",
    "print(\"Y_train shape: \" + str(train_set_y_orig.shape))\n",
    "print(\"X_dev shape: \" + str(dev_set_x_orig.shape))\n",
    "print(\"Y_dev shape: \" + str(dev_set_y_orig.shape))\n",
    "print(\"X_test shape: \" + str(test_set_x_orig.shape))\n",
    "print(\"Y_test shape: \" + str(test_set_y_orig.shape))\n",
    "\n",
    "print(\"Classes are: \" + str(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Check to visualize a randomly chosen image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly visualize some X\n",
    "\n",
    "for i in range(5):\n",
    "    index = np.random.randint(len(train_set_y_orig))\n",
    "    plt.figure(i, figsize=(5, 5))\n",
    "    plt.title(target_label[str(train_set_y_orig[index][0])])\n",
    "    plt.imshow(train_set_x_orig[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 7. Sample code for Mini-batch access for bigger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "hdf5_file = h5py.File(outfile_path, \"r\")\n",
    "\n",
    "batch_size = 32\n",
    "train_size = hdf5_file[\"train_set_x\"].shape[0]\n",
    "num_of_classes = len(classes)\n",
    "\n",
    "# create list of batches\n",
    "batches_list = list(range(int(ceil(float(train_size) / batch_size))))\n",
    "shuffle(batches_list)\n",
    "\n",
    "for n, i in enumerate(batches_list):\n",
    "    i_s = i * batch_size  # index of the first image in this batch\n",
    "    i_e = min([(i + 1) * batch_size, train_size])  # index of the last image in this batch\n",
    "    \n",
    "    # read batch images and remove training mean\n",
    "    images = hdf5_file[\"train_set_x\"][i_s:i_e, ...]\n",
    "\n",
    "    # read labels and convert to one hot encoding\n",
    "    labels = hdf5_file[\"train_set_y\"][i_s:i_e]\n",
    "    labels_one_hot = np.zeros((labels.shape[0], num_of_classes))\n",
    "    labels_one_hot[np.arange(labels.shape[0]), labels] = 1\n",
    "    \n",
    "    print n+1, '/', len(batches_list)\n",
    "    print labels[0], labels_one_hot[0, :]\n",
    "    plt.imshow(images[0])\n",
    "    plt.show()\n",
    "    \n",
    "    if n == 5:  # break after 5 batches\n",
    "        break\n",
    "\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "* Some notation and format inspired by Deep Learning Specialization from Coursera/deeplearning.ai. \n",
    "* http://machinelearninguru.com/deep_learning/data_preparation/hdf5/hdf5.html\n",
    "* https://docs.scipy.org/doc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
